# MemoryOS Implementation Strategy

## Overview

This document outlines the implementation strategy for Smith's MemoryOS, a sophisticated memory management system for AI agents inspired by operating system principles. MemoryOS addresses the limitations of fixed context windows in Large Language Models (LLMs) by providing a hierarchical storage architecture and intelligent memory management.

## Core Architecture

### Ash Domain Structure

MemoryOS will be implemented as a dedicated Ash domain with the following components:

```
MemoryOS
├── STM (Short-Term Memory)
│   └── DialoguePage
├── MTM (Mid-Term Memory)
│   └── DialogueSegment
├── LPM (Long-Term Personal Memory)
│   ├── ObjectPersona
│   └── AgentPersona
└── SystemMemory (Shared Knowledge)
```

### Resources Definition

#### 1. Short-Term Memory (STM)

**`MemoryOS.STM.DialoguePage` Resource:**

- **Purpose**: Stores recent conversation/interaction data
- **Key Attributes**:
  - `query`: Input from the external entity
  - `response`: Agent's response
  - `timestamp`: When the interaction occurred
  - `meta_chain`: Summary of context relevance generated by LLM
  - `agent_id`: Reference to the owning agent
- **Implementation Notes**:
  - Configured as a fixed-length queue per agent
  - Queue length is configurable per agent type

#### 2. Mid-Term Memory (MTM)

**`MemoryOS.MTM.DialogueSegment` Resource:**

- **Purpose**: Groups related DialoguePages by topic
- **Key Attributes**:
  - `topic_summary`: LLM-generated summary of segment content
  - `embedding`: Vector representation for similarity calculations
  - `keywords`: Set of keywords extracted by LLM
  - `heat_score`: Calculated engagement score
  - `visit_count`: Number of retrievals
  - `last_accessed`: Timestamp for recency factor
  - `agent_id`: Reference to the owning agent
- **Relationships**:
  - `has_many :dialogue_pages` - Links to STM pages
- **Implementation Notes**:
  - Maximum segment capacity configurable per agent
  - Heat score calculation parameters (α, β, γ) configurable

#### 3. Long-Term Personal Memory (LPM)

**`MemoryOS.LPM.ObjectPersona` Resource:**

- **Purpose**: Flexible storage for any entity the agent interacts with
- **Key Attributes**:
  - `type`: The type of entity (user, domain, product, etc.)
  - `identifier`: Unique identifier for the entity
  - `profile`: Flexible map of static attributes
  - `agent_id`: Reference to the owning agent
- **Relationships**:
  - `has_many :knowledge_base_entries` - Facts about this entity
  - `has_many :trait_entries` - Inferred traits/properties
- **Implementation Notes**:
  - Profile schema determined by entity type
  - Knowledge base and traits implemented as fixed-size queues
  - Queue sizes configurable per agent

**`MemoryOS.LPM.AgentPersona` Resource:**

- **Purpose**: Stores agent's own traits and history
- **Key Attributes**:
  - `profile`: Agent's core identity settings
  - `agent_id`: Reference to the agent itself
- **Relationships**:
  - `has_many :trait_entries` - Agent's evolving traits
- **Implementation Notes**:
  - Trait queue size configurable

#### 4. System Memory (Shared)

**`MemoryOS.SystemMemory` Resource:**

- **Purpose**: Cross-agent shared knowledge
- **Key Attributes**:
  - `content`: The shared knowledge/fact
  - `embedding`: Vector for similarity search
  - `source_agent_id`: Agent that contributed this entry
  - `importance_score`: Measure of global importance
  - `creation_timestamp`: When it was added
- **Implementation Notes**:
  - Accessible by all agents
  - Knowledge diffusion based on importance scoring

### Configuration System

All constants and thresholds will be configurable through a combination of:

1. **Application-wide defaults** in `config.exs`:

   ```elixir
   config :smith, MemoryOS,
     default_stm_capacity: 7,
     default_mtm_capacity: 200,
     default_object_kb_capacity: 100
   ```

2. **Agent-specific configurations** via a dedicated resource:

   ```elixir
   defmodule MemoryOS.Configuration do
     use Ash.Resource, data_layer: AshPostgres.DataLayer
     
     attributes do
       uuid_primary_key :id
       attribute :agent_id, :uuid
       attribute :agent_type, :string
       attribute :stm_capacity, :integer
       attribute :mtm_capacity, :integer
       attribute :mtm_fscore_threshold, :float
       attribute :heat_alpha, :float
       attribute :heat_beta, :float
       attribute :heat_gamma, :float
       attribute :heat_threshold, :float
       # etc.
     end
     
     # CRUD actions and validations
   end
   ```

## Key Algorithms and Processes

### 1. Fscore Calculation

The Fscore determines the similarity between a DialoguePage and a DialogueSegment, defined as:

```
Fscore = cos(e_s, e_p) + FJacard(K_s, K_p)
```

Implementation via Ash calculation:

```elixir
# Vector similarity using pgvector
calculation :cosine_similarity, :float, private?: true,
  calculate: fn segment, _context ->
    segment_embedding = segment.embedding
    page_embedding = segment.__private__.page_embedding
    fragment("cosine_similarity(?::vector, ?::vector)", 
      segment_embedding, 
      page_embedding)
  end

# Jaccard similarity between keyword sets
calculation :keyword_similarity, :float, private?: true,
  calculate: &MemoryOS.Calculations.jaccard_similarity/2

# Final Fscore combining both measures  
calculation :fscore, :float, 
  depends_on: [:cosine_similarity, :keyword_similarity],
  calculate: fn segment, _ ->
    segment.cosine_similarity + segment.keyword_similarity
  end
```

### 2. Heat Score Calculation

Heat determines the importance of a DialogueSegment, defined as:

```
Heat = α · N_visit + β · L_interaction + γ · R_recency
```

Implementation:

```elixir
calculation :recency_factor, :float, private?: true,
  calculate: fn segment, _context ->
    μ = segment.__private__.time_constant || 1.0e7
    delta_t = DateTime.diff(DateTime.utc_now(), segment.last_accessed, :second)
    :math.exp(-delta_t / μ)
  end

calculation :heat, :float,
  depends_on: [:visit_count, :page_count, :recency_factor],
  calculate: fn segment, _context ->
    config = MemoryOS.get_agent_config(segment.agent_id)
    
    α = config.heat_alpha
    β = config.heat_beta
    γ = config.heat_gamma
    
    α * segment.visit_count + 
    β * segment.page_count + 
    γ * segment.recency_factor
  end
```

### 3. STM-MTM Transfer Process

When a DialoguePage is pushed out of STM, it's integrated into MTM:

1. Calculate Fscore between page and existing segments
2. If best Fscore > threshold, merge into that segment
3. Otherwise, create a new segment
4. Update segment's topic summary

Implementation via Oban worker:

```elixir
defmodule MemoryOS.Workers.STMToMTM do
  use Oban.Worker, queue: :memory
  
  @impl Oban.Worker
  def perform(%{args: %{"page_id" => page_id}}) do
    # Transfer logic implemented via MemoryOS actions
    MemoryOS.transfer_page_to_mtm(page_id)
    :ok
  end
end
```

### 4. MTM Management Process

Periodically (e.g., every hour):

1. Calculate heat score for all segments
2. If MTM at capacity, evict segments with lowest heat
3. Transfer high-heat segments (heat > threshold) to LPM

### 5. LPM to SystemMemory Process

When important information emerges:

1. Agent's LPM extracts critical facts
2. Calculate importance_score for global relevance
3. Store in SystemMemory if score exceeds threshold
4. May eventually evict lower-importance entries if at capacity

## Integration with LLM Services

The LLM integration is abstracted behind a dedicated module:

```elixir
defmodule MemoryOS.LLMClient do
  @moduledoc """
  Service module for all LLM interactions
  """
  
  def generate_meta_chain(dialogue_pages) do
    # Call external LLM with appropriate prompt
  end
  
  def calculate_embedding(text) do
    # Get vector embedding of text
  end
  
  def extract_keywords(text) do
    # Extract key topics/concepts
  end
  
  def generate_segment_summary(pages) do
    # Summarize related pages
  end
  
  def extract_traits(dialogue_segment) do
    # Identify traits/preferences from dialogue
  end
  
  def generate_final_prompt(query, stm, mtm, lpm, system_memory) do
    # Construct the complete prompt with memory context
  end
end
```

This service will be implemented using `AshAI` for seamless integration.

## Memory Retrieval Process

When a query arrives, MemoryOS executes a multi-level retrieval:

1. **STM Retrieval**: Fetch all DialoguePages for the agent
2. **MTM Retrieval**: Two-stage process
   - Select top-m segments based on Fscore with query
   - From those segments, select top-k pages
3. **LPM Retrieval**:
   - Fetch relevant ObjectPersona information
   - Fetch relevant AgentPersona information
4. **SystemMemory Retrieval**:
   - Fetch relevant shared knowledge
5. **Response Generation**:
   - Combine all retrieved information
   - Structure appropriate prompt for LLM
   - Generate final response

## Implementation Phases

1. **Foundation**: Setup project, define resources
2. **Core Logic**: Implement key calculations and actions
3. **Memory Management**: Implement update processes and Oban workers
4. **Agent Integration**: Connect with AshAI
5. **Optimization & Testing**: Refine, test, document

## Technical Considerations

Read the python implementation here: <https://github.com/BAI-LAB/MemoryOS/tree/main/memoryos-mcp/memoryos> - especially the prompts: <https://github.com/BAI-LAB/MemoryOS/blob/main/memoryos-mcp/memoryos/prompts.py> to get a feel for how the implementation should look like.

### Vector Storage

All vector operations will leverage Ash's vector extension:

```elixir
  vectorize do
    full_text do
      text(fn record ->
        """
        Name: #{record.name}
        Biography: #{record.biography}
        """
      end)

      # When used_attributes are defined, embeddings will only be rebuilt when
      # the listed attributes are changed in an update action.
      used_attributes [:name, :biography]
    end

    strategy :ash_oban
    ash_oban_trigger_name :my_vectorize_trigger (default name is :ash_ai_update_embeddings)
    attributes(name: :vectorized_name, biography: :vectorized_biography)

    # See the section below on defining an embedding model
    embedding_model MyApp.OpenAiEmbeddingModel
  end

  oban do
    triggers do
      trigger :my_vectorize_trigger do
        action :ash_ai_update_embeddings
        worker_read_action :read
        worker_module_name __MODULE__.AshOban.Worker.UpdateEmbeddings
        scheduler_module_name __MODULE__.AshOban.Scheduler.UpdateEmbeddings
        scheduler_cron nil
        list_tenants MyApp.ListTenants
      end
    end
  end
```

A possible embedding module could look like this:

```elixir
  defmodule MyApp.OpenAiEmbeddingModel do
    use AshAi.EmbeddingModel

    @impl true
    def dimensions(_opts), do: 3072

    @impl true
    def generate(texts, _opts) do
      api_key = System.fetch_env!("OPEN_AI_API_KEY")

      headers = [
        {"Authorization", "Bearer #{api_key}"},
        {"Content-Type", "application/json"}
      ]

      body = %{
        "input" => texts,
        "model" => "text-embedding-3-large"
      }

      response =
        Req.post!("https://api.openai.com/v1/embeddings",
          json: body,
          headers: headers
        )

      case response.status do
        200 ->
          response.body["data"]
          |> Enum.map(fn %{"embedding" => embedding} -> embedding end)
          |> then(&{:ok, &1})

        _status ->
          {:error, response.body}
      end
    end
  end
```

### Background Processing

Scheduled tasks will use Ash's Oban integration:

1. FIFO management for STM
2. Periodic heat score calculations
3. Segment eviction and LPM transfers
4. SystemMemory maintenance

### Testing Strategy

1. Mock LLM client for deterministic testing
2. Unit tests for pure functions
3. Integration tests for memory flows
4. End-to-end tests for agent interactions
5. Performance benchmarks for retrieval operations

## Customization and Extension Points

The architecture is designed to be highly customizable:

1. **Agent-specific Configuration**: Per-agent memory sizes, thresholds
2. **Alternative Embedding Models**: Pluggable embedding services
3. **Custom Object Types**: Extendable ObjectPersona profiles
4. **Enhanced Scoring Functions**: Replaceable Fscore and Heat calculations

---

This implementation strategy provides a flexible, scalable approach to implementing MemoryOS using the Ash framework, with particular attention to configurability and the ability to handle various types of entities beyond just users.
